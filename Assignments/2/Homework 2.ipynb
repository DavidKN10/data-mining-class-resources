{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Homework 2\n",
    "### David Rivera-Chino"
   ],
   "id": "59f9c85145572173"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recitation Exercises",
   "id": "628ca948a1e635d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 Chapter 8\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 1: Given the database in Table 8.2\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{tid} & \\text{itemset}\\\\\n",
    "\\hline\n",
    "t_1 & ABCD \\\\\n",
    "t_2 & ACDF \\\\\n",
    "t_3 & ACDEG \\\\\n",
    "t_4 & ABDF \\\\\n",
    "t_5 & BCG \\\\\n",
    "t_6 & DFG \\\\\n",
    "t_7 & ABG \\\\\n",
    "t_8 & CDFG \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### a.) Using *minsup* = 3/8, show how the Apriori algorithm enumerates all frequent patters from this dataset.\n",
    "\n",
    "<br>\n",
    "\n",
    "Since there are eight transactions in the database, the minimum support count is: $minsupCount = minsup \\times 8 = \\frac{3}{8} \\times 8 = 3$\n",
    "\n",
    "<br>\n",
    "\n",
    "Frequency of each item across all transactions:\n",
    "<br>\n",
    "A: 5\n",
    "<br>\n",
    "B: 4\n",
    "<br>\n",
    "C: 5\n",
    "<br>\n",
    "D: 6\n",
    "<br>\n",
    "E: 1\n",
    "<br>\n",
    "F: 4\n",
    "<br>\n",
    "G: 5\n",
    "\n",
    "E does not meet the threshold of 3, so we drop it.\n",
    "\n",
    "Now we count the occurrence of 2-itemsets:\n",
    "AB: 3\n",
    "<br>\n",
    "AC: 3\n",
    "<br>\n",
    "AD: 4\n",
    "<br>\n",
    "AF: 2\n",
    "<br>\n",
    "AG: 2\n",
    "<br>\n",
    "BC: 2\n",
    "<br>\n",
    "BD: 2\n",
    "<br>\n",
    "BF: 1\n",
    "<br>\n",
    "BG: 2\n",
    "<br>\n",
    "CD: 4\n",
    "<br>\n",
    "CF: 2\n",
    "<br>\n",
    "CG: 3\n",
    "<br>\n",
    "DF: 4\n",
    "<br>\n",
    "DG: 3\n",
    "<br>\n",
    "FG: 2\n",
    "<br>\n",
    "Only {AB}, {AC}, {AD}, {CD}, {CG}, {DF}, {DG} meet the threshold, so the rest are dropped. \n",
    "\n",
    "Now we count the occurrences of 3-itemsets:\n",
    "ABC: 1\n",
    "ABD: 2\n",
    "ACD: 3\n",
    "ACG: 1\n",
    "ADF: 2\n",
    "ADG: 1\n",
    "CDG: 2\n",
    "CDF: 2\n",
    "DGF: 2\n",
    "\n",
    "<br>\n",
    "\n",
    "Only {ACD} meets the threshold, therefore the others are dropped. \n",
    "\n",
    "<br>\n",
    "\n",
    "Frequent itemsets:\n",
    "\n",
    "<br>\n",
    "\n",
    "1-itemsets: {A}, {B}, {C}, {D}, {F}, {G}\n",
    "<br>\n",
    "2-itemsets: {AB}, {AC}, {AD}, {CD}, {CG}, {DF}, {DG}, \n",
    "<br>\n",
    "3-itemsets: {ACD}\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### b.) With *minsup* = 2/8, show how FPGrowth enumerates the frequent itemsets. \n",
    "\n",
    "<br>\n",
    "\n",
    "Since there are eight transactions in the database, the minimum support count is: $minsupCount = minsup \\times 8 = \\frac{2}{8} \\times 8 = 2$\n",
    "\n",
    "<br>\n",
    "\n",
    "Frequent 1-itemsets with support count:\n",
    "\n",
    "<br>\n",
    "\n",
    "D: 6\n",
    "A: 5\n",
    "C: 5\n",
    "G: 5\n",
    "B: 4\n",
    "F: 4\n",
    "\n",
    "<br>\n",
    "\n",
    "the resultant list, after sorting the items in descending order is as follows:\n",
    "<br>\n",
    "L={{D:6}, {A:5}, {C:5}, {G:5}, {B:4},{F:4}}\n",
    "\n",
    "<br>\n",
    "\n",
    "Ordered frequent items:\n",
    "<br>\n",
    "DACB\n",
    "<br>\n",
    "DACF\n",
    "<br>\n",
    "DACG\n",
    "<br>\n",
    "DABF\n",
    "<br>\n",
    "CGB\n",
    "<br>\n",
    "DGF\n",
    "<br>\n",
    "AGB\n",
    "<br>\n",
    "DCGF\n",
    "\n",
    "<br>\n",
    "\n",
    "<p>\n",
    "    <img src=\"20240610_211802.jpg\" width=\"700\" height=\"500\">\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "Conditional pattern base for each item:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Items} & \\text{Conditional Pattern Base}\\\\\n",
    "\\hline\n",
    "F & \\{\\{DAC:1\\},\\{DAB:1\\},\\{DG:1\\},\\{DCG:1\\}\\} \\\\\n",
    "B & \\{\\{DAC:1\\},\\{DA:1\\},\\{CG:1\\},\\{AG:1\\}\\} \\\\\n",
    "G & \\{\\{DAC:1\\},\\{D:1\\},\\{DC:1\\},\\{C:1\\},\\{A:1\\}\\} \\\\\n",
    "C & \\{\\{DA:3\\},\\{D:1\\}\\} \\\\\n",
    "A & \\{\\{D:4\\}\\} \\\\\n",
    "D &  \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Conditional FP-tree from the conditional pattern base:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Conditional Pattern Base} & \\text{Conditional FP-Tree}\\\\\n",
    "\\hline\n",
    "\\{\\{DAC:1\\},\\{DAB:1\\},\\{DG:1\\},\\{DCG:1\\}\\} & <D:4,A:2>,<D:4,G:2>,<D:4,C:2> \\\\\n",
    "\\{\\{DAC:1\\},\\{DA:1\\},\\{CG:1\\},\\{AG:1\\}\\} & <A:3,D:2>,<C:2>,<G:2> \\\\\n",
    "\\{\\{DAC:1\\},\\{D:1\\},\\{DC:1\\},\\{C:1\\},\\{A:1\\}\\} & <C:3,D:2>,<D:3.C:2>,<A:2> \\\\\n",
    "\\{\\{DA:3\\},\\{D:1\\}\\} & <D:4> \\\\\n",
    "\\{\\{D:4\\}\\} & <D:4> \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Generate frequent patterns by concatenating item with frequent patterns in conditional FP-tree:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Conditional FP-Tree} & \\text{Frequent Pattern Generated}\\\\\n",
    "\\hline\n",
    "<D:4,A:2>,<D:4,G:2>,<D:4,C:2> & \\{D,F:4\\},\\{AF:2\\},\\{DAF:2\\}\\{GF:2\\},\\{DGF:2\\}\\{CF:2\\},\\{DCF:2\\} \\\\\n",
    "<A:3,D:2>,<C:2>,<G:2> & \\{AB:3\\},\\{BD:2\\},\\{ABD:2\\},\\{BC:2\\},\\{BG:2\\} \\\\\n",
    "<C:3,D:2>,<D:3.C:2>,<A:2> & \\{CG:3\\},\\{DG:3\\},\\{CDG:2\\},\\{AG:2\\} \\\\\n",
    "<D:4> & \\{CD:4\\} \\\\\n",
    "<D:4> & \\{AD:4\\} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 3: Given two $k$-itemsets $X_a = \\{x_1,...,x_{k-1}, x_a\\}$ and $X_b=\\{x_1, x_{k-1}, x_b\\}$ that share the common $(k-1)$-itemset $X=\\{x_1, x_2, ..., x_{k-1}\\}$ as a prefix, prove that \n",
    "\n",
    "<br>\n",
    "\n",
    "### $$sup(X_{ab})=sup(X_a)-|\\mathbf{d}(X_{ab})|$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### where $X_{ab}=X_a \\cup X_b$, and $\\mathbf{d}(X_{ab})$ is the diffset of $X_{ab}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The itemset $X_{ab}$ is formed by adding $X_b$ to $X_a$. Therefore, any transaction that contains $X_{ab}$ must also contain $X_a$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Since every transaction that contains $X_{ab}$ also contains $X_a$, we have:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$sup(X_{ab}) \\leq sup(X_a)$$ \n",
    "\n",
    "<br>\n",
    "\n",
    "However, $sup(X_{ab})$ will be exactly those transactions that contain $X_a$ and also contain $X_b$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The diffset $\\mathbf{d}(X_{ab})$ consists of transactions that contain $X_a$ but do not contain $X_{ab}$. In order words, they contain $X_a$ but not $X_b$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The total number of transactions that contain $X_a$ can be divided into two disjoint sets:\n",
    "<br>\n",
    "Transactions that contain $X_a$ and $X_b$ or transactions that contain $X_{ab}$.\n",
    "<br>\n",
    "Transactions that contain $X_a$ but do not contain $X_b$ or the diffset of $\\mathbf{d}(X_{ab})$\n",
    "\n",
    "<br>\n",
    "\n",
    "Hence, the total support of $X_a$ is the sum of the supports of these two disjoint sets. \n",
    "\n",
    "$$sup(X_a)=sup(X_{ab})+|d(X_{ab})|$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Rearranging the equation, we get:\n",
    "\n",
    "$$sup(X_{ab})=sup(X_a) - |d(X_{ab})|$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 4: Given the databse in table 8.4. Show all rules that one can generate from the set $ABE$.\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{tid} & \\text{itemset}\\\\\n",
    "\\hline\n",
    "t_1 & ACD \\\\\n",
    "t_2 & BCE \\\\\n",
    "t_3 & ABCE \\\\\n",
    "t_4 & BDE \\\\\n",
    "t_5 & ABCE \\\\\n",
    "t_6 & ABCD \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Frequent Set} & \\text{Support Count}\\\\\n",
    "\\hline\n",
    "\\{A\\} & 4 \\\\\n",
    "\\{B\\} & 5 \\\\\n",
    "\\{E\\} & 4 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Frequent Set} & \\text{Support Count}\\\\\n",
    "\\hline\n",
    "\\{A,B\\} & 3 \\\\\n",
    "\\{A,E\\} & 2 \\\\\n",
    "\\{B,E\\} & 4 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Frequent Set} & \\text{Support Count}\\\\\n",
    "\\hline\n",
    "\\{A,B,E\\} & 2 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\{A,B,E\\}$ Rules:\n",
    "\n",
    "<br>\n",
    "\n",
    "${A} \\Rightarrow {B,E} ; confidence = 2/4 = 50\\%$\n",
    "<br>\n",
    "${B} \\Rightarrow {A,E} ; confidence = 2/5 = 40\\%$\n",
    "<br>\n",
    "${E} \\Rightarrow {A,B} ; confidence = 2/4 = 50\\%$\n",
    "<br>\n",
    "${A,B} \\Rightarrow {E} ; confidence = 2/3 = 66\\%$\n",
    "<br>\n",
    "${A,E} \\Rightarrow {B} ; confidence = 2/2 = 100\\%$ \n",
    "<br>\n",
    "${B,G} \\Rightarrow {A} ; confidence = 2/4 = 50\\%$\n",
    "\n",
    "<br> \n"
   ],
   "id": "2221f2ee9e954cd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Chapter 9\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 1: True or false:\n",
    "\n",
    "### a.) Maximal frequent itemsets are sufficient to determine all frequent itemsets with their supports.\n",
    "\n",
    "<br>\n",
    "\n",
    "False. Frequent itemsets are not sufficient to determine all frequent itemsets with their supports. Maximal frequent itemsets these are the largest frequent itemsets such that none of their supersets are frequent. While they provide valuable information about the boundaries of frequent itemsets, they do not give the support counts of their subsets directly. To determine all frequent itemsets and their supports, we need not only the maximal frequent itemsets but also the supports of all their subsets. The support of a subset is not necessarily deducible from the support of the maximal frequent itemset alone without additional data. Knowing the maximal frequent itemsets does not provide a straightforward way to calculate the support of all frequent itemsets directly. The support for subsets of maximal frequent itemsets must still be explicitly counted or derived using additional information.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    " \n",
    "### b.) An itemset and its closure share the same set of transactions.\n",
    "\n",
    "<br>\n",
    "\n",
    "True. the closure of an itemset $X$, often denoted as $X^+$, is the largest itemset that includes $X$ and has the same support as $ùëã$. This means that the closure of $X$ includes all items that appear in exactly the same transactions as $X$. The support of an itemset $X$ is the number of transactions that contain all items in $X$. Since the closure $X^+$ is defined to have the same support as $X$, it means $X$ and $X^+$ are present in exactly the same transactions. Any transaction containing $X$ must also contain $X^+$ and vice versa. Therefore, an itemset $X$ and its closure $X^+$ are supported by the same set of transactions. \n",
    "\n",
    "<br>\n",
    "\n",
    "### c.) The set of all maximal frequent sets is a subset of the set of all closed frequent itemsets.\n",
    "\n",
    "<br>\n",
    "\n",
    "True. The set of all maximal frequent sets is indeed a subset of the set of all closed frequent itemsets. Maximal frequent itemsets are those that are not contained within any other frequent itemset, while closed frequent itemsets are those that have no superpatterns with the same support. \n",
    "\n",
    "<br>\n",
    "\n",
    "### d.) The set of all maximal frequent sets is the set of longest possible frequent itemsets.\n",
    "\n",
    "<br>\n",
    "\n",
    "False. The set of all maximal frequent sets is not necessarily the set of longest possible frequent itemsets. Maximal frequent itemsets are those that cannot be extended to include any more items while remaining frequent, but they may not be the longest possible itemsets. Length is not a criteria for being maximal. \n"
   ],
   "id": "aaf2a6ad868981b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.3 Chapter 12\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 1: Show that if $X$ and $Y$ are independent, then $conv(X \\rightarrow Y)=1$. \n",
    "\n",
    "<br>\n",
    "\n",
    "Our equation for conviction is:\n",
    "$$conv(X \\rightarrow Y) = \\frac{P(X) \\cdot P(\\neg Y)}{P(X \\neg Y)} = \\frac{1}{lift(X \\rightarrow \\neg Y)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The value of conviction is high if the joint probability $X \\neg Y$ is less than the expected probability of $X$ and $\\neg Y$ individually. The conviction is infinite if the confidence is one. When $X$ and $Y$ are independent, the there are no support values. Therefore, the conviction is 1. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 2: Show that if $X$ and $Y$ are independent, then $oddsratio(X \\rightarrow Y)=1$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's divide the database into two groups. Those that contain $X$ and those that do not. The odds ratio of $Y$ in these two groups is the following:\n",
    "\n",
    "$$oddsratio(Y|X)=\\frac{P(XY)/P(X)}{P(X \\neg Y)/P(X)}=\\frac{P(XY)}{P(X \\neg Y)}$$\n",
    "\n",
    "$$oddsratio(Y|\\neg X)=\\frac{P(\\neg XY)/P(\\neg X)}{P(\\neg X \\neg Y)/P(\\neg X)}=\\frac{P(\\neg XY)}{P(\\neg X \\neg Y)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This is the odds ratio of the two groups:\n",
    "\n",
    "$$oddsratio = \\frac{oddsratio(Y|X)}{oddsratio(Y| \\neg X)} = \\frac{sup(XY) sup(\\neg X \\neg Y)}{sup(X \\neg Y) sup(\\neg XY)}$$\n",
    "\n",
    "<br> \n",
    "\n",
    "When $X$ and $Y$ are independent, the odds ratio value for each is 1. When their values are close to one, there is very little dependence between them. Therefore, $oddsratio(X \\rightarrow Y) = 1$ when $X$ and $Y$ are independent. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercise 3: Show that for a frequent itemset $X$, the value of the relative lift statistic defined in Example 12.20 lies in the range\n",
    "$$[1-|\\mathbf{D} / minsup, 1|]$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Support} & \\text{No. of samples}\\\\\n",
    "\\hline\n",
    "10,000 & 5 \\\\\n",
    "15,000 & 20 \\\\\n",
    "20,000 & 40 \\\\\n",
    "25,000 & 50 \\\\\n",
    "30,000 & 20 \\\\\n",
    "35,000 & 50 \\\\\n",
    "40,000 & 5 \\\\\n",
    "45,000 & 10 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The relative lift is calculated as the relative change in lift value of itemset $X$ comparing the input database $D$ and randomized set $D_i$. \n",
    "$$rlift(X,D,D_i) = \\frac{lift(X,D)-lift(X,D_i)}{lift(X,D)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "the rlift can be defined for the $m$ datasets $X= \\{X_1, X_2,...,X_m \\}$\n",
    "$$lift(X,D)=rsup(X,D) / \\prod_{j=1}^{m} rsup(x_j, D)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The number of transactions does not change and the interchanging of the randomization process leads to the support of the item. The support of the randomized dataset $D_i$ is defined as:\n",
    "$$rsup(x_j, D) = rsup(x_j,D_i)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Here, $|D|=|D_i|$. The relative statistics with the input dataset and the randomized dataset is:\n",
    "$$rlift(X,D,D_i) = \\frac{sup(X,D)-sup(X,D_i)}{sup(X,D)} = 1 - \\frac{sup(X,D_i)}{sup(X,D)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This relative shift value depends on the randomized dataset and the average value one means the frequent pattern occurs in any randomized set in the range of:\n",
    "$$[1-|D|/minsup, 1]$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Therefore, the relative shift lies in $[1-|D|/minsup, 1]$ "
   ],
   "id": "bb26db0c9457e12b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "<br>\n",
    "\n",
    "https://www.geeksforgeeks.org/apriori-algorithm/\n",
    "\n",
    "<br>\n",
    "\n",
    "https://www.softwaretestinghelp.com/fp-growth-algorithm-data-mining/\n",
    "\n",
    "<br>\n",
    "\n",
    "https://www.geeksforgeeks.org/frequent-item-set-in-data-set-association-rule-mining/\n",
    "\n",
    "<br>\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S2314728816300460#:~:text=Conviction%20is%20defined%20as%2C%20Conviction,not%20appear%20in%20a%20transaction.\n",
    "\n",
    "<br>\n",
    "\n",
    "https://psychscenehub.com/psychpedia/odds-ratio-2/\n",
    "\n",
    "<br>\n",
    "\n",
    "https://www.datacamp.com/tutorial/association-rule-mining-python\n",
    "\n",
    "<br>\n",
    "\n",
    "ChatGPT\n",
    "\n",
    "<br>\n",
    "\n",
    "Textbook"
   ],
   "id": "a94849220f48daec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Practicum Problems",
   "id": "72d428074e755bd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 Problem 1\n",
    "\n",
    "### Load the Online Retail dataset (Online Retail.xlsx) from the UCI Machine Learning Repository into Python using a Pandas dataframe. Using the apriori module from the MLxtend library, generate Frequent Itemsets for all transactions for the country of France. What itemset has the largest support? Set the minimum support threshold to 5% and extract frequent itemsets, and use them as input to the association rules module. Use each of the confidence and lift metrics to extract the association rules with the highest values, respectively. What are the antecedents and consequents of each rule? Is the rule with the highest confidence the same as the rule with the highest lift? Why or why not?"
   ],
   "id": "4a428379fc377027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:00:13.414288Z",
     "start_time": "2024-06-16T19:59:33.681255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "#loading dataset\n",
    "data_frame = pd.read_excel(\"Online Retail.xlsx\")\n",
    "\n",
    "#filter the dataset for France\n",
    "data_frame_france = data_frame[data_frame[\"Country\"] == \"France\"]\n",
    "\n",
    "#prepare transactions\n",
    "transactions = data_frame_france.groupby(\"InvoiceNo\")[\"Description\"].apply(list)\n",
    "\n",
    "#using TransactionEncoder to transform list into an array for Mlxtend\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "dataframe_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "#use Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(dataframe_transactions, min_support=0.05, use_colnames=True)\n",
    "\n",
    "#generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "#display frequent itemset\n",
    "print(frequent_itemsets)\n",
    "print()\n",
    "\n",
    "#display the association rules\n",
    "print(rules)"
   ],
   "id": "c1921f95eb52180",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      support                                           itemsets\n",
      "0    0.060738                      (4 TRADITIONAL SPINNING TOPS)\n",
      "1    0.084599                       (ALARM CLOCK BAKELIKE GREEN)\n",
      "2    0.086768                        (ALARM CLOCK BAKELIKE PINK)\n",
      "3    0.080260                        (ALARM CLOCK BAKELIKE RED )\n",
      "4    0.058568                       (ASSORTED COLOUR MINI CASES)\n",
      "..        ...                                                ...\n",
      "125  0.071584  (POSTAGE, SET/6 RED SPOTTY PAPER CUPS, SET/20 ...\n",
      "126  0.071584  (POSTAGE, SET/6 RED SPOTTY PAPER PLATES, SET/2...\n",
      "127  0.086768  (SET/6 RED SPOTTY PAPER PLATES, POSTAGE, SET/6...\n",
      "128  0.084599  (SET/6 RED SPOTTY PAPER PLATES, SET/6 RED SPOT...\n",
      "129  0.069414  (SET/6 RED SPOTTY PAPER PLATES, POSTAGE, SET/6...\n",
      "\n",
      "[130 rows x 2 columns]\n",
      "\n",
      "                                           antecedents  \\\n",
      "0                          (ALARM CLOCK BAKELIKE PINK)   \n",
      "1                         (ALARM CLOCK BAKELIKE GREEN)   \n",
      "2                          (ALARM CLOCK BAKELIKE RED )   \n",
      "3                         (ALARM CLOCK BAKELIKE GREEN)   \n",
      "4                                            (POSTAGE)   \n",
      "..                                                 ...   \n",
      "182  (SET/6 RED SPOTTY PAPER CUPS, SET/20 RED RETRO...   \n",
      "183                    (SET/6 RED SPOTTY PAPER PLATES)   \n",
      "184                                          (POSTAGE)   \n",
      "185                      (SET/6 RED SPOTTY PAPER CUPS)   \n",
      "186              (SET/20 RED RETROSPOT PAPER NAPKINS )   \n",
      "\n",
      "                                           consequents  antecedent support  \\\n",
      "0                         (ALARM CLOCK BAKELIKE GREEN)            0.086768   \n",
      "1                          (ALARM CLOCK BAKELIKE PINK)            0.084599   \n",
      "2                         (ALARM CLOCK BAKELIKE GREEN)            0.080260   \n",
      "3                          (ALARM CLOCK BAKELIKE RED )            0.084599   \n",
      "4                         (ALARM CLOCK BAKELIKE GREEN)            0.674620   \n",
      "..                                                 ...                 ...   \n",
      "182           (SET/6 RED SPOTTY PAPER PLATES, POSTAGE)            0.086768   \n",
      "183  (POSTAGE, SET/6 RED SPOTTY PAPER CUPS, SET/20 ...            0.108460   \n",
      "184  (SET/6 RED SPOTTY PAPER PLATES, SET/6 RED SPOT...            0.674620   \n",
      "185  (SET/20 RED RETROSPOT PAPER NAPKINS , SET/6 RE...            0.117137   \n",
      "186  (SET/6 RED SPOTTY PAPER PLATES, SET/6 RED SPOT...            0.112798   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "0              0.084599  0.062907    0.725000  8.569872  0.055566    3.328732   \n",
      "1              0.086768  0.062907    0.743590  8.569872  0.055566    3.561605   \n",
      "2              0.084599  0.067245    0.837838  9.903673  0.060455    5.644975   \n",
      "3              0.080260  0.067245    0.794872  9.903673  0.060455    4.483731   \n",
      "4              0.084599  0.071584    0.106109  1.254267  0.014512    1.024064   \n",
      "..                  ...       ...         ...       ...       ...         ...   \n",
      "182            0.091106  0.069414    0.800000  8.780952  0.061509    4.544469   \n",
      "183            0.071584  0.069414    0.640000  8.940606  0.061650    2.578935   \n",
      "184            0.084599  0.069414    0.102894  1.216259  0.012342    1.020394   \n",
      "185            0.071584  0.069414    0.592593  8.278339  0.061029    2.278840   \n",
      "186            0.086768  0.069414    0.615385  7.092308  0.059627    2.374403   \n",
      "\n",
      "     zhangs_metric  \n",
      "0         0.967237  \n",
      "1         0.964945  \n",
      "2         0.977480  \n",
      "3         0.982113  \n",
      "4         0.623030  \n",
      "..             ...  \n",
      "182       0.970309  \n",
      "183       0.996198  \n",
      "184       0.546458  \n",
      "185       0.995854  \n",
      "186       0.968215  \n",
      "\n",
      "[187 rows x 10 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "alarm clock bakelike pink has the larges support\n",
    "\n",
    "<br>\n",
    "\n"
   ],
   "id": "2e25a59251240ed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Problem 2",
   "id": "820c69654bfa56ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "<br>\n",
    "\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/\n",
    "\n",
    "<br>\n",
    "\n",
    "https://medium.com/edureka/apriori-algorithm-d7cc648d4f1e\n",
    "\n",
    "<br>"
   ],
   "id": "66992fa131f222cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
